---
title: Multisensory
sidebar_position: 7
---

## Summary

The **multisensory** domain represents data and devices that engage multiple senses simultaneously, unifying visual, auditory, tactile, and other perceptual channels into one coherent experience. If the symbolic domain captures data before it becomes perceivable, the multisensory domain captures the opposite: the moment perception is fully integrated—when multiple sensory outputs merge into a single, intuitive whole.

This domain is foundational to the CatalystUI Model because it explains why modern computing feels seamless. A computer isn’t just a collection of separate outputs—graphics here, audio there, vibration somewhere else. It is a synchronized environment where these channels operate together, supporting and reinforcing one another. This realization grew out of the search for the underlying truth behind human–computer interaction, revealing why CatalystUI needed a place to represent how modern systems actually behave.

Today’s platforms—Windows, macOS, Linux, mobile operating systems, game consoles, and VR devices—are inherently multisensory. They coordinate visuals, audio, haptics, environmental data, and user input to create unified perception.

## Core Characteristics

Before reaching the human interface, modern devices merge multiple sensory streams into a single experience. The multisensory domain describes that point of integration.

- **Unified perception:** Multiple senses combine into one coherent experience rather than isolated outputs.
- **Device-driven integration:** This domain often describes what systems and hardware *provide*, not just the data itself.
- **Emergent behavior:** Perception is shaped by how visual, auditory, tactile, and environmental cues interact with one another.
- **Context-aware:** Depending on hardware capabilities, a device may offer a multisensory experience or only a single-sense output.
- **System-level integration:** Operating systems, windows, and runtime environments most often fall within this domain because of how they coordinate multiple sensory channels.

## Appearances in The Stack

Just as the Symbolic domain lives primarily in Layers 7 and 6, the multisensory domain appears in the lower half of the stack—where perception is delivered rather than defined.

- **Layer 3 and above:** Where visual, auditory, tactile, and other sensory outputs converge into unified perception.

- **Layer 2 — Window:** Windows typically represent multisensory interfaces, combining rendered visuals, audio playback, and haptic output when available.

- **Layer 1 — System:** Systems are nearly always multisensory. They orchestrate graphics, sound pipelines, haptics, input devices, sensors, and hardware capabilities in concert.

## Examples of Multisensory Data

### 1. Operating Systems (Windows, macOS, Linux)

Coordinated visuals, system audio, haptics, and notifications create unified perception.

### 2. VR and AR Systems

Blend immersive visuals, spatial audio, tactile feedback, and motion tracking into a single environment.

### 3. Game Consoles (PlayStation, Xbox, Switch)

Combine graphics, music, sound effects, controller vibration, and motion sensors into synchronized interaction.

### 4. Smartphones and Tablets

Visual UI, audio output, vibration feedback, and environmental sensors all work together in everyday interaction.

### 5. Multichannel Applications

Apps combining visuals, sound cues, and tactile responses—such as games or mobile interfaces with haptic confirmation.

### 6. Embedded Systems with Mixed Output

Vehicle dashboards, smart appliances, and kiosks that present information through displays, speakers, and physical controls.

### 7. Theatrical & Live-Event Systems (stage lighting, projection, sound, show control)

Large-scale productions blend synchronized lighting cues, multichannel audio, projection mapping, atmospheric effects, and sometimes haptic or environmental feedback into a unified experience. Stage consoles, DMX networks, MIDI timecode rigs, and show-control systems like QLab or OSC-based setups all operate multisensorily, coordinating multiple sensory outputs with precision.